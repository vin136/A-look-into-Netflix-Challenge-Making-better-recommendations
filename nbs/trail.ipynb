{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4a166dc5-b758-4731-8ed3-ac306d799a81",
      "metadata": {
        "id": "4a166dc5-b758-4731-8ed3-ac306d799a81"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bef5b576-3eb1-4551-98c5-54b41d171722",
      "metadata": {
        "id": "bef5b576-3eb1-4551-98c5-54b41d171722",
        "outputId": "9abe3b09-7544-4aa9-9ef0-30ab0982edf0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.cuda.is_available()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2664b357-1e26-4479-8d3f-01ec022cca37",
      "metadata": {
        "id": "2664b357-1e26-4479-8d3f-01ec022cca37",
        "outputId": "2caff211-dbd0-4384-8ece-fed3d69efaec"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.cuda.device_count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "69e0ff07-568f-45a9-98a0-fd1ab26c3223",
      "metadata": {
        "id": "69e0ff07-568f-45a9-98a0-fd1ab26c3223"
      },
      "outputs": [],
      "source": [
        "x = torch.FloatTensor([0,9,7])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "83502388-3da1-459b-953c-baa42b0bd18b",
      "metadata": {
        "id": "83502388-3da1-459b-953c-baa42b0bd18b"
      },
      "outputs": [],
      "source": [
        "x_gpu = x.cuda()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b9cb9b69-39d8-406b-a9de-feee5fb4e2be",
      "metadata": {
        "id": "b9cb9b69-39d8-406b-a9de-feee5fb4e2be",
        "outputId": "82c4c09c-52c6-494a-9df0-eb056244056a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([0., 9., 7.], device='cuda:0')"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x_gpu"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fff5cbac-d154-4286-a494-d9e96ead5dda",
      "metadata": {
        "id": "fff5cbac-d154-4286-a494-d9e96ead5dda"
      },
      "source": [
        "# Data Loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5e28faac-c141-4112-be5d-d148a33c9c64",
      "metadata": {
        "id": "5e28faac-c141-4112-be5d-d148a33c9c64"
      },
      "outputs": [],
      "source": [
        "#Looking at data\n",
        "\n",
        "data_dir = '/common/home/vk405/Projects/Crossmdl/Data/YouCookII/'\n",
        "import pandas as pd\n",
        "import os\n",
        "label = pd.read_csv(data_dir+'label_foodtype.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "79f47df1-7a5a-422d-9ad9-62197f5a04ff",
      "metadata": {
        "id": "79f47df1-7a5a-422d-9ad9-62197f5a04ff",
        "outputId": "f44892a3-b541-43f3-d682-79cf2183b418"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>101</th>\n",
              "      <th>BLT</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>102</td>\n",
              "      <td>onion rings</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>103</td>\n",
              "      <td>burger</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>104</td>\n",
              "      <td>scrambled eggs</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>105</td>\n",
              "      <td>fried chicken</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>106</td>\n",
              "      <td>macaroni and cheese</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   101                  BLT\n",
              "0  102          onion rings\n",
              "1  103               burger\n",
              "2  104       scrambled eggs\n",
              "3  105        fried chicken\n",
              "4  106  macaroni and cheese"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "label.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2d08ae9b",
      "metadata": {
        "id": "2d08ae9b",
        "outputId": "1a5ae0a2-04f1-47a5-dc0b-82131e4098b5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'/common/home/vk405/Projects/Crossmdl/Data/YouCookII/splits/'"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "splits_dir = data_dir+'splits/'\n",
        "splits = ['test_list.txt','train_list.txt','val_list.txt']\n",
        "splits_dir"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f63b028a-9dcf-42b4-92d3-115a1fd994ad",
      "metadata": {
        "id": "f63b028a-9dcf-42b4-92d3-115a1fd994ad"
      },
      "outputs": [],
      "source": [
        "def get_vids(base_dir,split):\n",
        "    trn_split = base_dir+split\n",
        "    trn_idlst = []\n",
        "    trn_vidlst = []\n",
        "\n",
        "    f = open(trn_split,'r')\n",
        "    for line in f:\n",
        "        id_,vid = line.split('/')\n",
        "        vid = vid.strip('\\n')\n",
        "        trn_idlst.append(id_)\n",
        "        trn_vidlst.append(vid)\n",
        "        #print(vid)\n",
        "        #break\n",
        "    f.close()\n",
        "    return trn_idlst,trn_vidlst"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d21a53fe-3920-4ec6-8b73-13dba5f9af75",
      "metadata": {
        "id": "d21a53fe-3920-4ec6-8b73-13dba5f9af75"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "159727b5",
      "metadata": {
        "id": "159727b5"
      },
      "outputs": [],
      "source": [
        "feat_dir = '/common/users/vk405/feat_csv'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4967867e-b051-4f0c-b36a-b385fadcf1e4",
      "metadata": {
        "id": "4967867e-b051-4f0c-b36a-b385fadcf1e4",
        "outputId": "08e07319-7715-4962-9299-4a67d31cb59f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "test_frame_feat_csv  train_frame_feat_csv  val_frame_feat_csv\n"
          ]
        }
      ],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a4ab8808",
      "metadata": {
        "id": "a4ab8808"
      },
      "outputs": [],
      "source": [
        "def get_features(data_dir,split='val',feat_dir='/common/users/vk405/feat_csv/'):\n",
        "    #feat_dir = data_dir\n",
        "    splits_dir = data_dir+'splits/'\n",
        "    if split == 'val':\n",
        "        feat_split_dir = feat_dir+'val_frame_feat_csv/'  \n",
        "        vid_num,vid_name = get_vids(splits_dir,'val_list.txt')  \n",
        "    elif split == 'train':\n",
        "        feat_split_dir = feat_dir+'train_frame_feat_csv/'  \n",
        "        vid_num,vid_name = get_vids(splits_dir,'train_list.txt') \n",
        "    elif split == 'test':\n",
        "        feat_split_dir = feat_dir+'test_frame_feat_csv/'  \n",
        "        vid_num,vid_name = get_vids(splits_dir,'test_list.txt')\n",
        "    else:\n",
        "        raise NotImplementedError(f'unknown split: {split}')     \n",
        "    feat_list = []\n",
        "    vid_dtls = []\n",
        "    for num,name in zip(vid_num,vid_name):\n",
        "        feat_loc = os.path.join(feat_split_dir, f'{num}/{name}/0001/')\n",
        "        #import pdb;pdb.set_trace()\n",
        "        if os.path.isdir(feat_loc):\n",
        "            feat_files = feat_loc + os.listdir(feat_loc)[0]\n",
        "            feat_list.append(feat_files)\n",
        "            vid_dtls.append((num,name))\n",
        "        else:\n",
        "            print(f\"video : {num}/{name} not found\")\n",
        "    return feat_list,vid_dtls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1f1e3a74-800c-4a41-93a0-679aad59e5a2",
      "metadata": {
        "id": "1f1e3a74-800c-4a41-93a0-679aad59e5a2"
      },
      "outputs": [],
      "source": [
        "trn_feats,trn_vids = get_features(data_dir,split='train')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "725f7b2e-8e77-4f00-9cb0-86564ed75067",
      "metadata": {
        "id": "725f7b2e-8e77-4f00-9cb0-86564ed75067",
        "outputId": "9016396c-7a5e-4d51-f910-0e5702360c1b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('405', 'Ysh60eirChU'),\n",
              " ('405', 'jpQBWsR3HHs'),\n",
              " ('405', 'QWXlKD-XGCQ'),\n",
              " ('405', '5E3kulJRzGY')]"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trn_vids[:4]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6d8182f0-039c-4b3d-9ba3-953594dc7e51",
      "metadata": {
        "id": "6d8182f0-039c-4b3d-9ba3-953594dc7e51",
        "outputId": "f8d41514-4f94-401a-b12c-64aedad453a8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['/common/users/vk405/feat_csv/train_frame_feat_csv/405/Ysh60eirChU/0001/resnet_34_feat_mscoco.csv',\n",
              " '/common/users/vk405/feat_csv/train_frame_feat_csv/405/jpQBWsR3HHs/0001/resnet_34_feat_mscoco.csv',\n",
              " '/common/users/vk405/feat_csv/train_frame_feat_csv/405/QWXlKD-XGCQ/0001/resnet_34_feat_mscoco.csv',\n",
              " '/common/users/vk405/feat_csv/train_frame_feat_csv/405/5E3kulJRzGY/0001/resnet_34_feat_mscoco.csv']"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trn_feats[:4]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "14f4ec1d-0a5f-4406-b2b1-7fc206c08c67",
      "metadata": {
        "id": "14f4ec1d-0a5f-4406-b2b1-7fc206c08c67"
      },
      "source": [
        "## Extracting labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b858e1c1-4b58-4a48-b110-11a416e7999a",
      "metadata": {
        "id": "b858e1c1-4b58-4a48-b110-11a416e7999a",
        "outputId": "42feeee6-9880-4db3-9f04-bcf928c83729"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0.23554123938084</th>\n",
              "      <th>0.38126820325851</th>\n",
              "      <th>0.037564814090729</th>\n",
              "      <th>0.33999225497246</th>\n",
              "      <th>0.079771302640438</th>\n",
              "      <th>0.16590736806393</th>\n",
              "      <th>0.044274087995291</th>\n",
              "      <th>0.24475057423115</th>\n",
              "      <th>0</th>\n",
              "      <th>0.058666735887527</th>\n",
              "      <th>...</th>\n",
              "      <th>0.084935463964939</th>\n",
              "      <th>0.01984204351902</th>\n",
              "      <th>0.32</th>\n",
              "      <th>0.097782678902149</th>\n",
              "      <th>0.066549979150295</th>\n",
              "      <th>0.027964554727077</th>\n",
              "      <th>0.07146405428648</th>\n",
              "      <th>0.2452535033226</th>\n",
              "      <th>0.57338571548462</th>\n",
              "      <th>0.107208378613</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.223362</td>\n",
              "      <td>0.522559</td>\n",
              "      <td>0.054025</td>\n",
              "      <td>0.235792</td>\n",
              "      <td>0.337412</td>\n",
              "      <td>0.071114</td>\n",
              "      <td>0.698125</td>\n",
              "      <td>0.454669</td>\n",
              "      <td>0.117050</td>\n",
              "      <td>0.400916</td>\n",
              "      <td>...</td>\n",
              "      <td>0.608820</td>\n",
              "      <td>0.098003</td>\n",
              "      <td>0.065165</td>\n",
              "      <td>0.009080</td>\n",
              "      <td>0.000075</td>\n",
              "      <td>0.177700</td>\n",
              "      <td>0.010139</td>\n",
              "      <td>0.240321</td>\n",
              "      <td>0.834141</td>\n",
              "      <td>0.531293</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.280908</td>\n",
              "      <td>0.799305</td>\n",
              "      <td>0.116399</td>\n",
              "      <td>0.149240</td>\n",
              "      <td>0.490649</td>\n",
              "      <td>0.493386</td>\n",
              "      <td>0.203430</td>\n",
              "      <td>0.271588</td>\n",
              "      <td>0.432822</td>\n",
              "      <td>0.227877</td>\n",
              "      <td>...</td>\n",
              "      <td>0.705037</td>\n",
              "      <td>0.407644</td>\n",
              "      <td>0.328168</td>\n",
              "      <td>0.064713</td>\n",
              "      <td>0.034681</td>\n",
              "      <td>0.718221</td>\n",
              "      <td>0.673627</td>\n",
              "      <td>0.113452</td>\n",
              "      <td>0.316431</td>\n",
              "      <td>0.316319</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.337408</td>\n",
              "      <td>0.787760</td>\n",
              "      <td>0.175948</td>\n",
              "      <td>0.201669</td>\n",
              "      <td>0.449441</td>\n",
              "      <td>0.568926</td>\n",
              "      <td>0.243045</td>\n",
              "      <td>0.220369</td>\n",
              "      <td>0.737802</td>\n",
              "      <td>0.207814</td>\n",
              "      <td>...</td>\n",
              "      <td>0.692446</td>\n",
              "      <td>0.500816</td>\n",
              "      <td>0.315559</td>\n",
              "      <td>0.016786</td>\n",
              "      <td>0.029962</td>\n",
              "      <td>0.545505</td>\n",
              "      <td>0.654320</td>\n",
              "      <td>0.106729</td>\n",
              "      <td>0.551245</td>\n",
              "      <td>0.189272</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.320235</td>\n",
              "      <td>0.798259</td>\n",
              "      <td>0.162805</td>\n",
              "      <td>0.165569</td>\n",
              "      <td>0.482295</td>\n",
              "      <td>0.588328</td>\n",
              "      <td>0.242836</td>\n",
              "      <td>0.243118</td>\n",
              "      <td>0.740177</td>\n",
              "      <td>0.206619</td>\n",
              "      <td>...</td>\n",
              "      <td>0.675599</td>\n",
              "      <td>0.469745</td>\n",
              "      <td>0.359901</td>\n",
              "      <td>0.011614</td>\n",
              "      <td>0.028526</td>\n",
              "      <td>0.611490</td>\n",
              "      <td>0.676336</td>\n",
              "      <td>0.115364</td>\n",
              "      <td>0.544628</td>\n",
              "      <td>0.194859</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.158559</td>\n",
              "      <td>0.524380</td>\n",
              "      <td>0.109580</td>\n",
              "      <td>0.487074</td>\n",
              "      <td>0.136141</td>\n",
              "      <td>0.003217</td>\n",
              "      <td>0.807754</td>\n",
              "      <td>0.140633</td>\n",
              "      <td>0.451391</td>\n",
              "      <td>0.053430</td>\n",
              "      <td>...</td>\n",
              "      <td>0.399409</td>\n",
              "      <td>0.149640</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.150264</td>\n",
              "      <td>0.011508</td>\n",
              "      <td>0.348237</td>\n",
              "      <td>0.253195</td>\n",
              "      <td>0.152878</td>\n",
              "      <td>0.720622</td>\n",
              "      <td>0.603298</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 512 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   0.23554123938084  0.38126820325851  0.037564814090729  0.33999225497246  \\\n",
              "0          0.223362          0.522559           0.054025          0.235792   \n",
              "1          0.280908          0.799305           0.116399          0.149240   \n",
              "2          0.337408          0.787760           0.175948          0.201669   \n",
              "3          0.320235          0.798259           0.162805          0.165569   \n",
              "4          0.158559          0.524380           0.109580          0.487074   \n",
              "\n",
              "   0.079771302640438  0.16590736806393  0.044274087995291  0.24475057423115  \\\n",
              "0           0.337412          0.071114           0.698125          0.454669   \n",
              "1           0.490649          0.493386           0.203430          0.271588   \n",
              "2           0.449441          0.568926           0.243045          0.220369   \n",
              "3           0.482295          0.588328           0.242836          0.243118   \n",
              "4           0.136141          0.003217           0.807754          0.140633   \n",
              "\n",
              "          0  0.058666735887527  ...  0.084935463964939  0.01984204351902  \\\n",
              "0  0.117050           0.400916  ...           0.608820          0.098003   \n",
              "1  0.432822           0.227877  ...           0.705037          0.407644   \n",
              "2  0.737802           0.207814  ...           0.692446          0.500816   \n",
              "3  0.740177           0.206619  ...           0.675599          0.469745   \n",
              "4  0.451391           0.053430  ...           0.399409          0.149640   \n",
              "\n",
              "       0.32  0.097782678902149  0.066549979150295  0.027964554727077  \\\n",
              "0  0.065165           0.009080           0.000075           0.177700   \n",
              "1  0.328168           0.064713           0.034681           0.718221   \n",
              "2  0.315559           0.016786           0.029962           0.545505   \n",
              "3  0.359901           0.011614           0.028526           0.611490   \n",
              "4  0.000000           0.150264           0.011508           0.348237   \n",
              "\n",
              "   0.07146405428648  0.2452535033226  0.57338571548462  0.107208378613  \n",
              "0          0.010139         0.240321          0.834141        0.531293  \n",
              "1          0.673627         0.113452          0.316431        0.316319  \n",
              "2          0.654320         0.106729          0.551245        0.189272  \n",
              "3          0.676336         0.115364          0.544628        0.194859  \n",
              "4          0.253195         0.152878          0.720622        0.603298  \n",
              "\n",
              "[5 rows x 512 columns]"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sample_feat = pd.read_csv(trn_feats[0])\n",
        "sample_feat.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "63576c1d-18fb-4a64-bb62-992e847fb661",
      "metadata": {
        "id": "63576c1d-18fb-4a64-bb62-992e847fb661"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "494ddbba-c04a-4d04-bfb7-7d6cf8c4f18b",
      "metadata": {
        "jupyter": {
          "source_hidden": true
        },
        "tags": [],
        "id": "494ddbba-c04a-4d04-bfb7-7d6cf8c4f18b"
      },
      "outputs": [],
      "source": [
        "shapes = []\n",
        "for file in val_feats:\n",
        "    f = pd.read_csv(file)\n",
        "    pres_shape = f.shape\n",
        "    if len(shapes):\n",
        "        if shapes[-1] != pres_shape:\n",
        "            print('shape mismatch')\n",
        "    shapes.append(pres_shape)\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "370762c8-8682-4aed-9e30-8f5aeb10bfce",
      "metadata": {
        "id": "370762c8-8682-4aed-9e30-8f5aeb10bfce"
      },
      "outputs": [],
      "source": [
        "annotns_file = data_dir+'annotations/youcookii_annotations_trainval.json'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3f10e9db-d035-4498-9611-9e1729a35f2f",
      "metadata": {
        "id": "3f10e9db-d035-4498-9611-9e1729a35f2f",
        "outputId": "5caf08f6-5e50-414a-bd89-fc5d7fda3b33"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "dict_keys(['database'])\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "\n",
        "\n",
        "def get_raw_labels(ids):\n",
        "\n",
        "    label_info = {}\n",
        "    with open(annotns_file) as json_file:\n",
        "        annotns = json.load(json_file)\n",
        "        print(annotns.keys())\n",
        "        for _,vidname in ids:\n",
        "            #import pdb;pdb.set_trace()\n",
        "            if vidname in annotns['database']:\n",
        "                #import pdb;pdb.set_trace()\n",
        "                duration = annotns['database'][vidname]['duration']\n",
        "                annot = annotns['database'][vidname]['annotations']\n",
        "                labels = []\n",
        "                #import pdb;pdb.set_trace()\n",
        "                for segment_info in annot:\n",
        "                    interval = segment_info['segment']\n",
        "                    sent = segment_info['sentence']\n",
        "                    labels.append((interval,sent,duration))\n",
        "\n",
        "                label_info[vidname] = labels\n",
        "            else:\n",
        "                print(f\"label for {vidname} not present\")\n",
        "    return label_info\n",
        "    \n",
        "    \n",
        "label_info = get_raw_labels(trn_vids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d3bfefe7-673c-4dbc-9e62-d5ac72552342",
      "metadata": {
        "id": "d3bfefe7-673c-4dbc-9e62-d5ac72552342",
        "outputId": "12072b02-459c-4353-949b-3576a0e3ac8f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[([120, 125], 'heat 2 tbsp ghee in a pan', 609.97),\n",
              " ([128, 198],\n",
              "  'add cinnamon bay leaves green cardamoms black cardamoms green chillies and saute',\n",
              "  609.97),\n",
              " ([222, 244], 'add onions and saute for 3-4 minutes', 609.97),\n",
              " ([263, 300], 'add mutton and saute for 2 minutes', 609.97),\n",
              " ([302, 308], 'add ginger-garlic paste and mix well', 609.97),\n",
              " ([309, 343],\n",
              "  'add salt 2 cup water and cover to pressure cook on high heat for 5 minutes',\n",
              "  609.97),\n",
              " ([395, 428],\n",
              "  'heat crushed peppercorns and cashew nut paste with remaining ghee in a pan',\n",
              "  609.97),\n",
              " ([475, 500],\n",
              "  'add the cooked mutton with stock and spices and mix everything well',\n",
              "  609.97),\n",
              " ([508, 529], 'add garam masala powder cream and stir to mix', 609.97),\n",
              " ([570, 573], 'sprinkle crushed peppercorns on top and serve', 609.97)]"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "label_info['Ysh60eirChU']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b324b40e-a15d-49ae-8810-eec851f608fb",
      "metadata": {
        "id": "b324b40e-a15d-49ae-8810-eec851f608fb"
      },
      "outputs": [],
      "source": [
        "intervals = []\n",
        "for ele in label_info.values():\n",
        "    for intv,_ ,_ in ele:\n",
        "        intervals.append(intv)\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0f6bc1fd-b137-49a5-ae77-fdd9f8f8cbf0",
      "metadata": {
        "id": "0f6bc1fd-b137-49a5-ae77-fdd9f8f8cbf0",
        "outputId": "fdfae54d-6db2-4e9f-db25-2e3a7f9623cb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(0, 1046)"
            ]
          },
          "execution_count": 57,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from itertools import chain\n",
        "\n",
        "min(list(chain(*intervals))),max(list(chain(*intervals)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3aed25b2-688b-478b-8a9c-a1411d1baf90",
      "metadata": {
        "id": "3aed25b2-688b-478b-8a9c-a1411d1baf90"
      },
      "outputs": [],
      "source": [
        "def regress_labels(raw_labels):\n",
        "    regress_labels = {}\n",
        "    for key in raw_labels:\n",
        "        new_labels = []\n",
        "        for item in raw_labels[key]:\n",
        "            rng,sent,vidlen = item\n",
        "            mid = sum(rng)/2\n",
        "            duration = rng[-1]-rng[0]\n",
        "            mid_pred = (1/vidlen)*mid # location of mid-point w.r.t video length\n",
        "            duration_pred = (1/vidlen)*duration\n",
        "            new_labels.append(([mid_pred,duration_pred],sent))\n",
        "        regress_labels[key] = new_labels\n",
        "    return regress_labels\n",
        "            \n",
        "            \n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "27082d67-11f0-4eb2-9bde-3ddf347bb01c",
      "metadata": {
        "id": "27082d67-11f0-4eb2-9bde-3ddf347bb01c"
      },
      "outputs": [],
      "source": [
        "final_labels = regress_labels(label_info)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9f704a03-45ae-4f05-9da5-55b465f4102d",
      "metadata": {
        "id": "9f704a03-45ae-4f05-9da5-55b465f4102d",
        "outputId": "4e69eca2-ebf5-45bd-8fad-146454219e12"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[([0.20082954899421282, 0.00819712444874338], 'heat 2 tbsp ghee in a pan'),\n",
              " ([0.2672262570290342, 0.11475974228240732],\n",
              "  'add cinnamon bay leaves green cardamoms black cardamoms green chillies and saute'),\n",
              " ([0.3819859993114415, 0.03606734757447087],\n",
              "  'add onions and saute for 3-4 minutes'),\n",
              " ([0.46149810646425227, 0.060658720920701015],\n",
              "  'add mutton and saute for 2 minutes'),\n",
              " ([0.5000245913733462, 0.009836549338492056],\n",
              "  'add ginger-garlic paste and mix well'),\n",
              " ([0.5344525140580684, 0.05574044625145498],\n",
              "  'add salt 2 cup water and cover to pressure cook on high heat for 5 minutes'),\n",
              " ([0.6746233421315802, 0.05410102136170631],\n",
              "  'heat crushed peppercorns and cashew nut paste with remaining ghee in a pan'),\n",
              " ([0.7992196337524795, 0.0409856222437169],\n",
              "  'add the cooked mutton with stock and spices and mix everything well'),\n",
              " ([0.8500418053346885, 0.034427922684722195],\n",
              "  'add garam masala powder cream and stir to mix'),\n",
              " ([0.9369313244913683, 0.004918274669246028],\n",
              "  'sprinkle crushed peppercorns on top and serve')]"
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "final_labels['Ysh60eirChU']"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4f118083-7f9f-4b8b-8bdd-3c5b85d06d9c",
      "metadata": {
        "id": "4f118083-7f9f-4b8b-8bdd-3c5b85d06d9c"
      },
      "source": [
        "# EDA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "712b908f-995a-4675-8211-3b6c9f1e9539",
      "metadata": {
        "id": "712b908f-995a-4675-8211-3b6c9f1e9539"
      },
      "outputs": [],
      "source": [
        "# Text length statistics - train\n",
        "\n",
        "label_info"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a072f022-f0dc-48b4-8a7a-28a48fa3c35c",
      "metadata": {
        "id": "a072f022-f0dc-48b4-8a7a-28a48fa3c35c"
      },
      "outputs": [],
      "source": [
        "from collections import defaultdict\n",
        "def extract_stats(label_dict,tokenizer=None):\n",
        "    txt_len = []\n",
        "    duration = []\n",
        "    total_len = []\n",
        "    vocab = defaultdict(int)\n",
        "    for key in label_dict:\n",
        "        for i,ele in enumerate(label_dict[key]):\n",
        "            rng,sent,tot_ln = ele\n",
        "            if tokenizer:\n",
        "                words = tokenizer.tokenize(sent)\n",
        "            else:\n",
        "                words = sent.split(' ')\n",
        "            for wrd in words:\n",
        "                vocab[wrd] += 1\n",
        "            txt_len.append(len(words))\n",
        "            duration.append(rng[-1]-rng[0])\n",
        "            if i==0:\n",
        "                total_len.append(tot_ln)\n",
        "    return {'txt_len':txt_len,'duration':duration,'total_len':total_len,'vocab':vocab}\n",
        "            \n",
        "                \n",
        "            "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "97a2e4c8-c0c8-49e8-ac8c-f7f067243d82",
      "metadata": {
        "id": "97a2e4c8-c0c8-49e8-ac8c-f7f067243d82"
      },
      "outputs": [],
      "source": [
        "stats = extract_stats(label_info)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b60d29d2-26d8-4ae4-8d7f-e9175c3d0b64",
      "metadata": {
        "id": "b60d29d2-26d8-4ae4-8d7f-e9175c3d0b64"
      },
      "outputs": [],
      "source": [
        "from collections import Counter\n",
        "\n",
        "txt_lens = Counter(stats['txt_len'])\n",
        "txt_df = pd.DataFrame({'lens':list(txt_lens.keys()),'freq':list(txt_lens.values())})\n",
        "\n",
        "\n",
        "duration_lens = Counter(stats['duration'])\n",
        "duration_df = pd.DataFrame({'lens':list(duration_lens.keys()),'freq':list(duration_lens.values())})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5300bd06-c201-4e21-9666-f86494040364",
      "metadata": {
        "id": "5300bd06-c201-4e21-9666-f86494040364"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d0f95f52-72d3-4b14-8279-71f8713c3a50",
      "metadata": {
        "id": "d0f95f52-72d3-4b14-8279-71f8713c3a50",
        "outputId": "7e6e31b3-c7f5-4134-c8bf-096d94eb445e"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "<div id=\"altair-viz-71de03648f534d119220f8ec5c8f9660\"></div>\n",
              "<script type=\"text/javascript\">\n",
              "  (function(spec, embedOpt){\n",
              "    let outputDiv = document.currentScript.previousElementSibling;\n",
              "    if (outputDiv.id !== \"altair-viz-71de03648f534d119220f8ec5c8f9660\") {\n",
              "      outputDiv = document.getElementById(\"altair-viz-71de03648f534d119220f8ec5c8f9660\");\n",
              "    }\n",
              "    const paths = {\n",
              "      \"vega\": \"https://cdn.jsdelivr.net/npm//vega@5?noext\",\n",
              "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm//vega-lib?noext\",\n",
              "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm//vega-lite@4.8.1?noext\",\n",
              "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm//vega-embed@6?noext\",\n",
              "    };\n",
              "\n",
              "    function loadScript(lib) {\n",
              "      return new Promise(function(resolve, reject) {\n",
              "        var s = document.createElement('script');\n",
              "        s.src = paths[lib];\n",
              "        s.async = true;\n",
              "        s.onload = () => resolve(paths[lib]);\n",
              "        s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
              "        document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
              "      });\n",
              "    }\n",
              "\n",
              "    function showError(err) {\n",
              "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
              "      throw err;\n",
              "    }\n",
              "\n",
              "    function displayChart(vegaEmbed) {\n",
              "      vegaEmbed(outputDiv, spec, embedOpt)\n",
              "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
              "    }\n",
              "\n",
              "    if(typeof define === \"function\" && define.amd) {\n",
              "      requirejs.config({paths});\n",
              "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
              "    } else if (typeof vegaEmbed === \"function\") {\n",
              "      displayChart(vegaEmbed);\n",
              "    } else {\n",
              "      loadScript(\"vega\")\n",
              "        .then(() => loadScript(\"vega-lite\"))\n",
              "        .then(() => loadScript(\"vega-embed\"))\n",
              "        .catch(showError)\n",
              "        .then(() => displayChart(vegaEmbed));\n",
              "    }\n",
              "  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-6eee1c701eead1b6aed4da77345e9502\"}, \"mark\": \"bar\", \"encoding\": {\"x\": {\"type\": \"quantitative\", \"field\": \"lens\"}, \"y\": {\"type\": \"quantitative\", \"field\": \"freq\"}}, \"$schema\": \"https://vega.github.io/schema/vega-lite/v4.8.1.json\", \"datasets\": {\"data-6eee1c701eead1b6aed4da77345e9502\": [{\"lens\": 7, \"freq\": 1244}, {\"lens\": 12, \"freq\": 510}, {\"lens\": 6, \"freq\": 1609}, {\"lens\": 16, \"freq\": 188}, {\"lens\": 13, \"freq\": 421}, {\"lens\": 9, \"freq\": 903}, {\"lens\": 10, \"freq\": 810}, {\"lens\": 11, \"freq\": 640}, {\"lens\": 17, \"freq\": 166}, {\"lens\": 8, \"freq\": 1058}, {\"lens\": 4, \"freq\": 358}, {\"lens\": 3, \"freq\": 429}, {\"lens\": 5, \"freq\": 1056}, {\"lens\": 18, \"freq\": 104}, {\"lens\": 15, \"freq\": 223}, {\"lens\": 14, \"freq\": 320}, {\"lens\": 19, \"freq\": 99}, {\"lens\": 20, \"freq\": 116}, {\"lens\": 2, \"freq\": 25}, {\"lens\": 21, \"freq\": 32}, {\"lens\": 24, \"freq\": 3}, {\"lens\": 23, \"freq\": 2}, {\"lens\": 22, \"freq\": 8}, {\"lens\": 25, \"freq\": 2}, {\"lens\": 27, \"freq\": 2}, {\"lens\": 44, \"freq\": 1}, {\"lens\": 41, \"freq\": 1}, {\"lens\": 37, \"freq\": 2}, {\"lens\": 39, \"freq\": 1}, {\"lens\": 26, \"freq\": 2}, {\"lens\": 30, \"freq\": 2}]}}, {\"mode\": \"vega-lite\"});\n",
              "</script>"
            ],
            "text/plain": [
              "alt.Chart(...)"
            ]
          },
          "execution_count": 100,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import altair as alt\n",
        "\n",
        "alt.Chart(txt_df).mark_bar().encode(\n",
        "    x='lens',\n",
        "    y='freq'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "618d6cba-dc8e-4412-92ae-20489bc0b1c1",
      "metadata": {
        "id": "618d6cba-dc8e-4412-92ae-20489bc0b1c1",
        "outputId": "4c1d1277-96a7-422a-9277-3ba9b8e75a5b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "<div id=\"altair-viz-1baf437809a049fa85296a3673346620\"></div>\n",
              "<script type=\"text/javascript\">\n",
              "  (function(spec, embedOpt){\n",
              "    let outputDiv = document.currentScript.previousElementSibling;\n",
              "    if (outputDiv.id !== \"altair-viz-1baf437809a049fa85296a3673346620\") {\n",
              "      outputDiv = document.getElementById(\"altair-viz-1baf437809a049fa85296a3673346620\");\n",
              "    }\n",
              "    const paths = {\n",
              "      \"vega\": \"https://cdn.jsdelivr.net/npm//vega@5?noext\",\n",
              "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm//vega-lib?noext\",\n",
              "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm//vega-lite@4.8.1?noext\",\n",
              "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm//vega-embed@6?noext\",\n",
              "    };\n",
              "\n",
              "    function loadScript(lib) {\n",
              "      return new Promise(function(resolve, reject) {\n",
              "        var s = document.createElement('script');\n",
              "        s.src = paths[lib];\n",
              "        s.async = true;\n",
              "        s.onload = () => resolve(paths[lib]);\n",
              "        s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
              "        document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
              "      });\n",
              "    }\n",
              "\n",
              "    function showError(err) {\n",
              "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
              "      throw err;\n",
              "    }\n",
              "\n",
              "    function displayChart(vegaEmbed) {\n",
              "      vegaEmbed(outputDiv, spec, embedOpt)\n",
              "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
              "    }\n",
              "\n",
              "    if(typeof define === \"function\" && define.amd) {\n",
              "      requirejs.config({paths});\n",
              "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
              "    } else if (typeof vegaEmbed === \"function\") {\n",
              "      displayChart(vegaEmbed);\n",
              "    } else {\n",
              "      loadScript(\"vega\")\n",
              "        .then(() => loadScript(\"vega-lite\"))\n",
              "        .then(() => loadScript(\"vega-embed\"))\n",
              "        .catch(showError)\n",
              "        .then(() => displayChart(vegaEmbed));\n",
              "    }\n",
              "  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-2986d9e2edb14270551cd5a1f1ad5951\"}, \"mark\": \"bar\", \"encoding\": {\"x\": {\"type\": \"quantitative\", \"field\": \"lens\"}, \"y\": {\"type\": \"quantitative\", \"field\": \"freq\"}}, \"$schema\": \"https://vega.github.io/schema/vega-lite/v4.8.1.json\", \"datasets\": {\"data-2986d9e2edb14270551cd5a1f1ad5951\": [{\"lens\": 5, \"freq\": 483}, {\"lens\": 70, \"freq\": 7}, {\"lens\": 22, \"freq\": 192}, {\"lens\": 37, \"freq\": 67}, {\"lens\": 6, \"freq\": 419}, {\"lens\": 34, \"freq\": 69}, {\"lens\": 33, \"freq\": 90}, {\"lens\": 25, \"freq\": 186}, {\"lens\": 21, \"freq\": 181}, {\"lens\": 3, \"freq\": 320}, {\"lens\": 41, \"freq\": 43}, {\"lens\": 23, \"freq\": 189}, {\"lens\": 43, \"freq\": 47}, {\"lens\": 31, \"freq\": 99}, {\"lens\": 28, \"freq\": 151}, {\"lens\": 14, \"freq\": 367}, {\"lens\": 12, \"freq\": 380}, {\"lens\": 27, \"freq\": 135}, {\"lens\": 9, \"freq\": 461}, {\"lens\": 17, \"freq\": 251}, {\"lens\": 13, \"freq\": 359}, {\"lens\": 10, \"freq\": 474}, {\"lens\": 16, \"freq\": 310}, {\"lens\": 19, \"freq\": 242}, {\"lens\": 24, \"freq\": 186}, {\"lens\": 20, \"freq\": 233}, {\"lens\": 58, \"freq\": 24}, {\"lens\": 18, \"freq\": 285}, {\"lens\": 2, \"freq\": 231}, {\"lens\": 8, \"freq\": 417}, {\"lens\": 4, \"freq\": 394}, {\"lens\": 42, \"freq\": 61}, {\"lens\": 7, \"freq\": 451}, {\"lens\": 39, \"freq\": 70}, {\"lens\": 30, \"freq\": 130}, {\"lens\": 35, \"freq\": 73}, {\"lens\": 36, \"freq\": 70}, {\"lens\": 11, \"freq\": 407}, {\"lens\": 52, \"freq\": 34}, {\"lens\": 32, \"freq\": 95}, {\"lens\": 90, \"freq\": 7}, {\"lens\": 29, \"freq\": 116}, {\"lens\": 15, \"freq\": 335}, {\"lens\": 65, \"freq\": 13}, {\"lens\": 83, \"freq\": 3}, {\"lens\": 53, \"freq\": 33}, {\"lens\": 82, \"freq\": 8}, {\"lens\": 26, \"freq\": 151}, {\"lens\": 1, \"freq\": 74}, {\"lens\": 40, \"freq\": 71}, {\"lens\": 48, \"freq\": 51}, {\"lens\": 79, \"freq\": 8}, {\"lens\": 44, \"freq\": 41}, {\"lens\": 75, \"freq\": 7}, {\"lens\": 127, \"freq\": 2}, {\"lens\": 160, \"freq\": 1}, {\"lens\": 55, \"freq\": 31}, {\"lens\": 76, \"freq\": 13}, {\"lens\": 61, \"freq\": 12}, {\"lens\": 64, \"freq\": 16}, {\"lens\": 60, \"freq\": 19}, {\"lens\": 78, \"freq\": 10}, {\"lens\": 51, \"freq\": 35}, {\"lens\": 46, \"freq\": 43}, {\"lens\": 38, \"freq\": 53}, {\"lens\": 69, \"freq\": 9}, {\"lens\": 99, \"freq\": 4}, {\"lens\": 57, \"freq\": 24}, {\"lens\": 50, \"freq\": 37}, {\"lens\": 47, \"freq\": 33}, {\"lens\": 45, \"freq\": 62}, {\"lens\": 67, \"freq\": 13}, {\"lens\": 49, \"freq\": 28}, {\"lens\": 63, \"freq\": 23}, {\"lens\": 66, \"freq\": 10}, {\"lens\": 81, \"freq\": 4}, {\"lens\": 93, \"freq\": 5}, {\"lens\": 100, \"freq\": 1}, {\"lens\": 56, \"freq\": 16}, {\"lens\": 59, \"freq\": 20}, {\"lens\": 85, \"freq\": 5}, {\"lens\": 101, \"freq\": 3}, {\"lens\": 264, \"freq\": 1}, {\"lens\": 94, \"freq\": 6}, {\"lens\": 86, \"freq\": 4}, {\"lens\": 54, \"freq\": 21}, {\"lens\": 104, \"freq\": 1}, {\"lens\": 80, \"freq\": 7}, {\"lens\": 112, \"freq\": 1}, {\"lens\": 113, \"freq\": 3}, {\"lens\": 87, \"freq\": 4}, {\"lens\": 62, \"freq\": 23}, {\"lens\": 73, \"freq\": 10}, {\"lens\": 72, \"freq\": 14}, {\"lens\": 71, \"freq\": 13}, {\"lens\": 108, \"freq\": 3}, {\"lens\": 96, \"freq\": 3}, {\"lens\": 92, \"freq\": 7}, {\"lens\": 68, \"freq\": 6}, {\"lens\": 125, \"freq\": 3}, {\"lens\": 115, \"freq\": 4}, {\"lens\": 89, \"freq\": 3}, {\"lens\": 95, \"freq\": 4}, {\"lens\": 123, \"freq\": 3}, {\"lens\": 91, \"freq\": 2}, {\"lens\": 168, \"freq\": 1}, {\"lens\": 102, \"freq\": 2}, {\"lens\": 139, \"freq\": 4}, {\"lens\": 153, \"freq\": 2}, {\"lens\": 88, \"freq\": 3}, {\"lens\": 74, \"freq\": 8}, {\"lens\": 147, \"freq\": 1}, {\"lens\": 135, \"freq\": 2}, {\"lens\": 130, \"freq\": 1}, {\"lens\": 122, \"freq\": 1}, {\"lens\": 103, \"freq\": 1}, {\"lens\": 84, \"freq\": 2}, {\"lens\": 118, \"freq\": 2}, {\"lens\": 120, \"freq\": 4}, {\"lens\": 97, \"freq\": 5}, {\"lens\": 107, \"freq\": 1}, {\"lens\": 77, \"freq\": 4}, {\"lens\": 98, \"freq\": 3}, {\"lens\": 188, \"freq\": 1}, {\"lens\": 157, \"freq\": 1}, {\"lens\": 128, \"freq\": 1}, {\"lens\": 178, \"freq\": 1}, {\"lens\": 116, \"freq\": 1}, {\"lens\": 126, \"freq\": 2}, {\"lens\": 132, \"freq\": 1}, {\"lens\": 140, \"freq\": 1}, {\"lens\": 110, \"freq\": 1}, {\"lens\": 242, \"freq\": 1}]}}, {\"mode\": \"vega-lite\"});\n",
              "</script>"
            ],
            "text/plain": [
              "alt.Chart(...)"
            ]
          },
          "execution_count": 110,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import altair as alt\n",
        "\n",
        "alt.Chart(duration_df).mark_bar().encode(\n",
        "    x='lens',\n",
        "    y='freq'\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aa136f60-3c83-42a5-ba55-e043361e1933",
      "metadata": {
        "id": "aa136f60-3c83-42a5-ba55-e043361e1933"
      },
      "outputs": [],
      "source": [
        "vocab_stats = pd.DataFrame({'words':list(stats['vocab'].keys()),'freq':list(stats['vocab'].values())})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "35fbb8a9-94f2-4417-80bd-e5b7c2bc93b3",
      "metadata": {
        "id": "35fbb8a9-94f2-4417-80bd-e5b7c2bc93b3"
      },
      "outputs": [],
      "source": [
        "total_cnt = sum(vocab_stats.sort_values(by='freq',ascending=False)['freq'])\n",
        "\n",
        "vocab_stats['frac_contrib'] = vocab_stats['freq']/total_cnt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2eb8eef6-b019-4532-aae8-76b0c5f9cac0",
      "metadata": {
        "id": "2eb8eef6-b019-4532-aae8-76b0c5f9cac0"
      },
      "outputs": [],
      "source": [
        "sorted_vocab = vocab_stats.sort_values(by='freq',ascending=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0d231f1c-e844-4e30-8f18-4b4f82912c42",
      "metadata": {
        "id": "0d231f1c-e844-4e30-8f18-4b4f82912c42"
      },
      "outputs": [],
      "source": [
        "sorted_vocab['cum_frac'] = sorted_vocab['frac_contrib'].cumsum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "72c550c1-38d7-474c-8f30-3b5aabd9b5da",
      "metadata": {
        "id": "72c550c1-38d7-474c-8f30-3b5aabd9b5da",
        "outputId": "2db75ced-5a4f-4cfd-ff8a-990b41345da4"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>words</th>\n",
              "      <th>freq</th>\n",
              "      <th>frac_contrib</th>\n",
              "      <th>cum_frac</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>the</td>\n",
              "      <td>9451</td>\n",
              "      <td>0.104037</td>\n",
              "      <td>0.104037</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>and</td>\n",
              "      <td>7350</td>\n",
              "      <td>0.080909</td>\n",
              "      <td>0.184945</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>add</td>\n",
              "      <td>4151</td>\n",
              "      <td>0.045694</td>\n",
              "      <td>0.230640</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>to</td>\n",
              "      <td>2865</td>\n",
              "      <td>0.031538</td>\n",
              "      <td>0.262178</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>a</td>\n",
              "      <td>2494</td>\n",
              "      <td>0.027454</td>\n",
              "      <td>0.289632</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>640</th>\n",
              "      <td>smoked</td>\n",
              "      <td>11</td>\n",
              "      <td>0.000121</td>\n",
              "      <td>0.949418</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>310</th>\n",
              "      <td>cherry</td>\n",
              "      <td>11</td>\n",
              "      <td>0.000121</td>\n",
              "      <td>0.949539</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>715</th>\n",
              "      <td>squares</td>\n",
              "      <td>11</td>\n",
              "      <td>0.000121</td>\n",
              "      <td>0.949660</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1475</th>\n",
              "      <td>scramble</td>\n",
              "      <td>11</td>\n",
              "      <td>0.000121</td>\n",
              "      <td>0.949781</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>744</th>\n",
              "      <td>sumac</td>\n",
              "      <td>11</td>\n",
              "      <td>0.000121</td>\n",
              "      <td>0.949903</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>575 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         words  freq  frac_contrib  cum_frac\n",
              "42         the  9451      0.104037  0.104037\n",
              "15         and  7350      0.080909  0.184945\n",
              "7          add  4151      0.045694  0.230640\n",
              "30          to  2865      0.031538  0.262178\n",
              "5            a  2494      0.027454  0.289632\n",
              "...        ...   ...           ...       ...\n",
              "640     smoked    11      0.000121  0.949418\n",
              "310     cherry    11      0.000121  0.949539\n",
              "715    squares    11      0.000121  0.949660\n",
              "1475  scramble    11      0.000121  0.949781\n",
              "744      sumac    11      0.000121  0.949903\n",
              "\n",
              "[575 rows x 4 columns]"
            ]
          },
          "execution_count": 125,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sorted_vocab[sorted_vocab['cum_frac']<0.95]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e32ed230-6999-4924-8dc2-c7811c034335",
      "metadata": {
        "id": "e32ed230-6999-4924-8dc2-c7811c034335"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "81497307-59a8-4095-bde8-02be804353c4",
      "metadata": {
        "id": "81497307-59a8-4095-bde8-02be804353c4"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "81baf9a0-15ac-4a14-90ff-74c703d10f1b",
      "metadata": {
        "id": "81baf9a0-15ac-4a14-90ff-74c703d10f1b"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "08b048e2-8fd0-40cb-821a-16b2758200fb",
      "metadata": {
        "id": "08b048e2-8fd0-40cb-821a-16b2758200fb"
      },
      "outputs": [],
      "source": [
        "# Tokenization and other text specific handling.\n",
        "#!pip install datasets  # You can install custom packages on Google Colab by !pip install ... \n",
        "#!pip install transformers\n",
        "#nltk.download()\n",
        "\n",
        "\n",
        "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
        "\n",
        "class Tokenizer:\n",
        "    def __init__(self, tokenize_type='basic', lowercase=False,stopwords=None):\n",
        "        self.tokenize_type = tokenize_type\n",
        "        self.lowercase = lowercase\n",
        "        self.digits = set([str(i) for i in range(10)])\n",
        "        if stopwords:\n",
        "            self.digits.update(stopwords)\n",
        "        if self.tokenize_type == 'wp':\n",
        "            self.wptok = BertTokenizer.from_pretrained('bert-base-cased')\n",
        "            \n",
        "\n",
        "    def tokenize(self, string):\n",
        "        if self.lowercase:\n",
        "            string = string.lower()\n",
        "        if self.tokenize_type == 'basic':\n",
        "            tokens = string.split()\n",
        "        elif self.tokenize_type == 'nltk':\n",
        "            tokens = nltk.tokenize.word_tokenize(string)\n",
        "        elif self.tokenize_type == 'wp':\n",
        "            tokens = self.wptok.tokenize(string)\n",
        "        else:\n",
        "            raise ValueError('Unknown tokenization type.')\n",
        "        tokens = [tok for tok in tokens if tok not in self.digits]\n",
        "        return tokens\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8a557253-8657-4cfc-9818-16601d8e2bc4",
      "metadata": {
        "id": "8a557253-8657-4cfc-9818-16601d8e2bc4"
      },
      "outputs": [],
      "source": [
        "tknr = Tokenizer(lowercase=True,stopwords=ENGLISH_STOP_WORDS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "19c1d3ec-abd2-4a24-a85a-237aadee0d47",
      "metadata": {
        "id": "19c1d3ec-abd2-4a24-a85a-237aadee0d47",
        "outputId": "754b77db-03e2-4139-cb30-f0e65bc7bdfd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "*****************\n",
            "heat 2 tbsp ghee in a pan\n",
            "['heat', 'tbsp', 'ghee', 'pan']\n",
            "*****************\n",
            "add cinnamon bay leaves green cardamoms black cardamoms green chillies and saute\n",
            "['add', 'cinnamon', 'bay', 'leaves', 'green', 'cardamoms', 'black', 'cardamoms', 'green', 'chillies', 'saute']\n",
            "*****************\n",
            "add onions and saute for 3-4 minutes\n",
            "['add', 'onions', 'saute', '3-4', 'minutes']\n",
            "*****************\n",
            "add mutton and saute for 2 minutes\n",
            "['add', 'mutton', 'saute', 'minutes']\n",
            "*****************\n",
            "add ginger-garlic paste and mix well\n",
            "['add', 'ginger-garlic', 'paste', 'mix']\n",
            "*****************\n",
            "add salt 2 cup water and cover to pressure cook on high heat for 5 minutes\n",
            "['add', 'salt', 'cup', 'water', 'cover', 'pressure', 'cook', 'high', 'heat', 'minutes']\n",
            "*****************\n",
            "heat crushed peppercorns and cashew nut paste with remaining ghee in a pan\n",
            "['heat', 'crushed', 'peppercorns', 'cashew', 'nut', 'paste', 'remaining', 'ghee', 'pan']\n",
            "*****************\n",
            "add the cooked mutton with stock and spices and mix everything well\n",
            "['add', 'cooked', 'mutton', 'stock', 'spices', 'mix']\n",
            "*****************\n",
            "add garam masala powder cream and stir to mix\n",
            "['add', 'garam', 'masala', 'powder', 'cream', 'stir', 'mix']\n",
            "*****************\n",
            "sprinkle crushed peppercorns on top and serve\n",
            "['sprinkle', 'crushed', 'peppercorns', 'serve']\n"
          ]
        }
      ],
      "source": [
        "samplevid = final_labels['Ysh60eirChU']\n",
        "\n",
        "for ele in samplevid:\n",
        "    _,sent = ele\n",
        "    tokens = tknr.tokenize(sent)\n",
        "    print('*****************')\n",
        "    print(sent)\n",
        "    print(tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9ec26408-f252-4553-bd63-4a428d29690c",
      "metadata": {
        "id": "9ec26408-f252-4553-bd63-4a428d29690c"
      },
      "outputs": [],
      "source": [
        "# lets look at word statistics with tokenization\n",
        "tknr = Tokenizer(lowercase=True,stopwords=ENGLISH_STOP_WORDS)\n",
        "stats_updtd = extract_stats(label_info,tokenizer=tknr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9b312033-c485-491f-8089-9a134f54e576",
      "metadata": {
        "id": "9b312033-c485-491f-8089-9a134f54e576"
      },
      "outputs": [],
      "source": [
        "\n",
        "vocab_stats_updtd = pd.DataFrame({'words':list(stats_updtd['vocab'].keys()),'freq':list(stats_updtd['vocab'].values())})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d18680b7-a39d-4e08-ac84-c206e4be44a6",
      "metadata": {
        "id": "d18680b7-a39d-4e08-ac84-c206e4be44a6",
        "outputId": "398502df-500e-46b1-fbc1-22f12c7e8e1b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1306"
            ]
          },
          "execution_count": 184,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sum(vocab_stats_updtd['freq']>=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6ada8948-1e30-47b4-92cb-7a05019c8eb8",
      "metadata": {
        "id": "6ada8948-1e30-47b4-92cb-7a05019c8eb8"
      },
      "source": [
        "We might just need around 1000 tokens."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ad1aec01-a393-466c-9e53-e82dd1a9c748",
      "metadata": {
        "id": "ad1aec01-a393-466c-9e53-e82dd1a9c748",
        "outputId": "ce9bf212-ddd6-43d5-920c-72788ab1b4e3"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>words</th>\n",
              "      <th>freq</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>ginger-garlic</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>nut</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61</th>\n",
              "      <td>leavese</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62</th>\n",
              "      <td>colves</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>64</th>\n",
              "      <td>turmac</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            words  freq\n",
              "17  ginger-garlic     1\n",
              "30            nut     1\n",
              "61        leavese     1\n",
              "62         colves     1\n",
              "64         turmac     1"
            ]
          },
          "execution_count": 189,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vocab_stats_updtd[vocab_stats_updtd['freq']<2].head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d69b9f83-36b0-4de2-b531-6cad7de1f1f5",
      "metadata": {
        "id": "d69b9f83-36b0-4de2-b531-6cad7de1f1f5"
      },
      "source": [
        "# SANITY CHECK"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a766da9a-2a68-4558-9222-394925edbcab",
      "metadata": {
        "id": "a766da9a-2a68-4558-9222-394925edbcab"
      },
      "outputs": [],
      "source": [
        "#trn_feats,trn_vids,final_labels\n",
        "import torch\n",
        "import numpy as np\n",
        "import random\n",
        "def set_seed(seed):  # For reproducibility, fix random seeds.\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "set_seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "099c4f13-c1e6-4d22-b2da-962e6725dba9",
      "metadata": {
        "id": "099c4f13-c1e6-4d22-b2da-962e6725dba9"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d2950fd9-0afd-4b93-8333-90fff787b4f3",
      "metadata": {
        "id": "d2950fd9-0afd-4b93-8333-90fff787b4f3"
      },
      "outputs": [],
      "source": [
        "sample_feat = pd.read_csv(trn_feats[0]).values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "12ae537a-6f93-4615-be65-a85de38a5737",
      "metadata": {
        "id": "12ae537a-6f93-4615-be65-a85de38a5737",
        "outputId": "7bc50cd5-7c36-46ea-fd1d-568839247ac7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(499, 512)"
            ]
          },
          "execution_count": 193,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sample_feat.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bc61ff36-1f2e-45f7-85d0-85c2ea736124",
      "metadata": {
        "id": "bc61ff36-1f2e-45f7-85d0-85c2ea736124"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8259b97a-030e-49bf-b34c-cbe517dd933d",
      "metadata": {
        "id": "8259b97a-030e-49bf-b34c-cbe517dd933d"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modeling"
      ],
      "metadata": {
        "id": "mwKdQnCNCqa_"
      },
      "id": "mwKdQnCNCqa_"
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import math\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as tfunc"
      ],
      "metadata": {
        "id": "ZCFt7eKVCs2i"
      },
      "id": "ZCFt7eKVCs2i",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here I will try to write all the key building blocks for a transformer encoder. As I suspect that this will be a part of any model we will be building, I take time to thoroughly implement all the blocks."
      ],
      "metadata": {
        "id": "ghLn1N6SD3zS"
      },
      "id": "ghLn1N6SD3zS"
    },
    {
      "cell_type": "code",
      "source": [
        "def scaled_dot(query, key, mask_key=None):  \n",
        "  score = torch.matmul(query, key.transpose(-2, -1))\n",
        "  score /= math.sqrt(query.size(-1))\n",
        "  if mask_key is not None:\n",
        "    score = score.masked_fill(mask_key, -1e18)  # Represents negative infinity\n",
        "  return score"
      ],
      "metadata": {
        "id": "7ZyqbjLgEKDd"
      },
      "id": "7ZyqbjLgEKDd",
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = torch.randn(3,10)\n",
        "key = torch.randn(5,10)\n",
        "values = torch.randn(5,10)\n",
        "\n",
        "score = scaled_dot(query,key)"
      ],
      "metadata": {
        "id": "GGva2p6lFiEJ"
      },
      "id": "GGva2p6lFiEJ",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "score.shape"
      ],
      "metadata": {
        "id": "I4jFc-0UF66C",
        "outputId": "c6cc9749-8066-476a-8cff-844b34dcc24e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "I4jFc-0UF66C",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 5])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tfunc.softmax(score,dim=-1)"
      ],
      "metadata": {
        "id": "5ftp4NDeGXgL",
        "outputId": "d1933d5d-d310-405c-88e4-2ad84c364f1f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "5ftp4NDeGXgL",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.0730, 0.1516, 0.6732, 0.0529, 0.0493],\n",
              "        [0.1442, 0.0461, 0.0063, 0.1601, 0.6432],\n",
              "        [0.0466, 0.0323, 0.7735, 0.1053, 0.0424]])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#We will also do attention dropout, meaning *after* computing softmax we apply a dropout layer on probabilities (if not None).\n",
        "#This may make the softmax output an invalid distribution, but is found helpful as \n",
        "#regularization. \n",
        "def attend(query, key, value, mask_key=None, dropout=None):\n",
        "  score = scaled_dot(query,key,mask_key)  \n",
        "  attention = tfunc.softmax(score,dim=-1)\n",
        "  if dropout is not None:\n",
        "    #do = nn.Dropout(dropout)\n",
        "    attention = dropout(attention)\n",
        "  answer = torch.matmul(attention,value) \n",
        "  # Convexly combine value embeddings using attention, this should be just a matrix-matrix multiplication.\n",
        "  return answer, attention"
      ],
      "metadata": {
        "id": "zduR-4DoF_9X"
      },
      "id": "zduR-4DoF_9X",
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_values,attention = attend(query,key,values)"
      ],
      "metadata": {
        "id": "F8_rlLq_IKRe"
      },
      "id": "F8_rlLq_IKRe",
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_values.shape"
      ],
      "metadata": {
        "id": "X3I2JZNpIW2D",
        "outputId": "546248a9-5808-4976-e30b-687c854ec5bf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "X3I2JZNpIW2D",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 10])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally let's implement multi-head attention. This is now a module with learnable parameters. First we will define some helper functions for splitting and merging vectors efficiently. In particular, splitting incurs no new memory allocation, because we simply reshape tensors. "
      ],
      "metadata": {
        "id": "y4vQF6XWIgPn"
      },
      "id": "y4vQF6XWIgPn"
    },
    {
      "cell_type": "code",
      "source": [
        "def split_heads(batch,num_heads):\n",
        "  (batch_size,length,dim) = batch.size()\n",
        "  assert dim%num_heads == 0, f\"num_heads :{num_heads} is not a multiple of dim:{dim}\"\n",
        "  dim_head = dim//num_heads\n",
        "  splitted = batch.view(batch_size,-1,num_heads,dim_head).transpose(1,2)\n",
        "  # (batch_size, num_heads, length, dim_head), note that now the last two dimensions are \n",
        "  #compatible with our attention functions. \n",
        "  return splitted"
      ],
      "metadata": {
        "id": "WZQaeuDfIg6W"
      },
      "id": "WZQaeuDfIg6W",
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def merge_heads(batch):  \n",
        "  (batch_size, num_heads, length, dim_head) = batch.size()  # These are the expected batch dimensions.\n",
        "\n",
        "  # New memory allocation (reshape), can't avoid.\n",
        "  merged = batch.transpose(1, 2).reshape(batch_size, -1, num_heads * dim_head)\n",
        "  return merged  # (batch_size, length, dim)"
      ],
      "metadata": {
        "id": "qN4UsBavKRPX"
      },
      "id": "qN4UsBavKRPX",
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "\n",
        "  def __init__(self, dim, num_heads, dropout_rate=0.1):\n",
        "    super().__init__()\n",
        "    assert dim % num_heads == 0\n",
        "\n",
        "    self.linear_query = nn.Linear(dim, dim)\n",
        "    self.linear_key = nn.Linear(dim, dim)\n",
        "    self.linear_value = nn.Linear(dim, dim)\n",
        "    self.linear_final = nn.Linear(dim, dim)\n",
        "    self.dropout = nn.Dropout(dropout_rate)\n",
        "\n",
        "    self.num_heads = num_heads\n",
        "\n",
        "  def forward(self, query, key, value, mask_key=None, layer_cache=None,\n",
        "              memory_attention=False):\n",
        "    \"\"\"\n",
        "    INPUT\n",
        "      query: (batch_size, length_query, dim)\n",
        "      key: (batch_size, length_key, dim)\n",
        "      value: (batch_size, length_key, dim_value)\n",
        "      mask_key: (*, 1, length_key) if queries share the same mask, else\n",
        "                (*, length_query, length_key)\n",
        "      layer_cache: if not None, stepwise decoding (cache of key/value)\n",
        "      memory_attention: doing memory attention in stepwise decoding?\n",
        "    OUTPUT\n",
        "      answer: (batch_size, length_query, dim_value)\n",
        "      attention: (batch_size, num_heads, length_query, length_key) else\n",
        "    \"\"\"\n",
        "    batch_size = query.size(0)\n",
        "\n",
        "    query = self.linear_query(query)\n",
        "    query = split_heads(query, self.num_heads)  # (batch_size, num_heads, -1, dim_head)\n",
        "\n",
        "    def process_key_value(key, value):  # Only called when necessary.\n",
        "      key = self.linear_key(key)\n",
        "      key = split_heads(key, self.num_heads)\n",
        "      value = self.linear_value(value)\n",
        "      value = split_heads(value, self.num_heads)\n",
        "      return key, value\n",
        "\n",
        "    #import pdb;pdb.set_trace()\n",
        "    if layer_cache is None:\n",
        "      key, value = process_key_value(key, value)\n",
        "    else:\n",
        "      assert query.size(2) == 1  # Stepwise decoding\n",
        "\n",
        "      if memory_attention:\n",
        "        if layer_cache['memory_key'] is None:  # One-time calculation\n",
        "          key, value = process_key_value(key, value)\n",
        "\n",
        "          # (batch_size, num_heads, length_memory, dim)\n",
        "          layer_cache['memory_key'] = key\n",
        "          layer_cache['memory_value'] = value\n",
        "\n",
        "        key = layer_cache['memory_key']\n",
        "        value = layer_cache['memory_value']\n",
        "\n",
        "      else:  # Self-attention during decoding\n",
        "        key, value = process_key_value(key, value)\n",
        "        assert key.size(2) == 1 and value.size(2) == 1\n",
        "\n",
        "        # Append to previous.\n",
        "        if layer_cache['self_key'] is not None:\n",
        "          key = torch.cat((layer_cache['self_key'], key), dim=2)\n",
        "          value = torch.cat((layer_cache['self_value'], value), dim=2)\n",
        "\n",
        "        # (batch_size, num_heads, length_decoded, dim)\n",
        "        layer_cache['self_key'] = key  # Recache.\n",
        "        layer_cache['self_value'] = value\n",
        "\n",
        "    # Because we've splitted embeddings into heads, we must also split the mask. \n",
        "    # And because each query uses the same mask for all heads (we don't use different masking for different heads), \n",
        "    # we can specify length 1 for the head dimension.\n",
        "    if mask_key is not None:  \n",
        "      mask_key = mask_key.unsqueeze(1)  # (batch_size, 1, -1, length_key)\n",
        "\n",
        "    answer, attention = attend(query, key, value, mask_key, self.dropout)\n",
        "\n",
        "    answer = merge_heads(answer)  # (batch_size, length_key, dim)\n",
        "    answer = self.linear_final(answer)\n",
        "\n",
        "    return answer, attention"
      ],
      "metadata": {
        "id": "pSGyKHlLKeiV"
      },
      "id": "pSGyKHlLKeiV",
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SinusoidalPositioner(nn.Module):\n",
        "\n",
        "  def __init__(self, dim, drop_rate=0.1, length_max=5000):\n",
        "    super().__init__()\n",
        "    frequency = torch.exp(torch.arange(0, dim, 2) * -(math.log(10000.) / dim))  \n",
        "    # Using different frequency for each dim\n",
        "    positions = torch.arange(0, length_max).unsqueeze(1)\n",
        "    wave = torch.zeros(length_max, dim)\n",
        "    wave[:, 0::2] = torch.sin(frequency * positions)\n",
        "    wave[:, 1::2] = torch.cos(frequency * positions)\n",
        "    self.register_buffer('wave', wave.unsqueeze(0))  # (1, length_max, dim)\n",
        "    self.dropout = nn.Dropout(drop_rate)\n",
        "    self.dim = dim\n",
        "    self.length_max = length_max\n",
        "\n",
        "  def forward(self, x, step=-1):\n",
        "    assert x.size(-2) <= self.length_max\n",
        "\n",
        "    if step < 0:  # Take the corresponding leftmost embeddings.\n",
        "      position_encoding = self.wave[:, :x.size(-2), :]\n",
        "    else:  # Take the embedding at the step.\n",
        "      position_encoding = self.wave[:, step, :]\n",
        "\n",
        "    x = x * math.sqrt(self.dim)\n",
        "    return self.dropout(x + position_encoding)\n",
        "\n",
        "positioner = SinusoidalPositioner(4, drop_rate=0., length_max=5)"
      ],
      "metadata": {
        "id": "O85hJWVHOGSy"
      },
      "id": "O85hJWVHOGSy",
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We're almost ready to define the encoder. Now that we have the most important building block of multi-head attention, it's pretty straightforward. The Transformer layer additionally uses a typically quite large nonlinear layer, so let's define that first. Importantly, within each layer, **the same nonlinear layer is applied for all positions**. This parameter sharing is what enables Transformer to handle arbitrary lengths."
      ],
      "metadata": {
        "id": "PKRcOe0iOa0y"
      },
      "id": "PKRcOe0iOa0y"
    },
    {
      "cell_type": "code",
      "source": [
        "class PositionwiseFeedForward(nn.Module):\n",
        "\n",
        "  def __init__(self, dim, dim_hidden, drop_rate=0.1):\n",
        "    super().__init__()\n",
        "    self.w1 = nn.Linear(dim, dim_hidden)\n",
        "    self.w2 = nn.Linear(dim_hidden, dim)\n",
        "    self.layer_norm = nn.LayerNorm(dim, eps=1e-6)\n",
        "    self.drop1 = nn.Dropout(drop_rate)\n",
        "    self.relu = nn.ReLU()\n",
        "    self.drop2 = nn.Dropout(drop_rate)\n",
        "\n",
        "  def forward(self, x):\n",
        "    inter = self.drop1(self.relu(self.w1(self.layer_norm(x))))\n",
        "    output = self.drop2(self.w2(inter))\n",
        "    return output + x"
      ],
      "metadata": {
        "id": "xf6420sSORP0"
      },
      "id": "xf6420sSORP0",
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Include a cross attention layer here instead of self-attention.\n",
        "\n",
        "\n",
        "\n",
        "class TransformerEncoderLayer(nn.Module):\n",
        "\n",
        "  def __init__(self, dim, num_heads, dim_hidden, drop_rate):\n",
        "    super().__init__()\n",
        "    self.layer_norm = nn.LayerNorm(dim, eps=1e-6)\n",
        "    self.self_attention = MultiHeadAttention(dim, num_heads, drop_rate)\n",
        "    self.drop = nn.Dropout(drop_rate)\n",
        "    self.feedforward = PositionwiseFeedForward(dim, dim_hidden, drop_rate)\n",
        "\n",
        "  def forward(self, source, mask_source=None):\n",
        "    # TODO: Implement\n",
        "    #print(source.shape)\n",
        "    normed = self.layer_norm(source)  \n",
        "    # Apply layer norm on source\n",
        "\n",
        "    attended, attention = self.self_attention(normed,normed,normed,mask_source)\n",
        "    #None, None  # Apply self-attention on normed (be sure to use mask_source).\n",
        "    attended = self.drop(attended) + source  \n",
        "    # Re-write attended by applying dropout and adding a residual connection to source.\n",
        "    return self.feedforward(attended), attention"
      ],
      "metadata": {
        "id": "8hE_WJdHOize"
      },
      "id": "8hE_WJdHOize",
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerEncoder(nn.Module):\n",
        "\n",
        "  def __init__(self, dim, num_heads, dim_hidden, drop_rate, num_layers):\n",
        "    super().__init__()\n",
        "    self.layers = nn.ModuleList([TransformerEncoderLayer(dim, num_heads, dim_hidden, drop_rate) for _ in range(num_layers)])\n",
        "    self.layer_norm = nn.LayerNorm(dim, eps=1e-6)\n",
        "\n",
        "  def forward(self, source, mask_source=None):\n",
        "    out = source\n",
        "    self_attentions = []\n",
        "    for layer in self.layers:\n",
        "      out, attention = layer(out, mask_source)\n",
        "      self_attentions.append(attention)\n",
        "    return self.layer_norm(out), self_attentions"
      ],
      "metadata": {
        "id": "hUdfxIYYOj7n"
      },
      "id": "hUdfxIYYOj7n",
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "kc7muwyiO96R"
      },
      "id": "kc7muwyiO96R",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.6",
      "language": "python",
      "name": "python3.6"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "name": "trail.ipynb",
      "provenance": [],
      "toc_visible": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}